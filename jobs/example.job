#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=IPC
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=20:00:00
#SBATCH --output=outputs/IPC/slurm_output_%A_simple.out

module purge
module load 2022
module load Anaconda3/2022.05

cd /home/etatar/GraphPredCod2/scr

# Activate your environment

source activate PredCod

# experiment 1: own params 
echo "Running simple training"

echo "----IPC----"

# experiment 1: own params 
echo "Running simple training"

srun python -u train.py \
    --mode training \
    --use_wandb online \
    --model_type IPC \
    --normalize_msg False \
    --dataset_transform none \
    --numbers_list 0,1,3,4,5,6,7 \
    --N 20 \
    --supervision_label_val 10 \
    --num_internal_nodes 1500 \
    --graph_type fully_connected \
    --weight_init 0.001 \
    --T 5 \
    --lr_values 0.1 \
    --lr_weights 0.00001 \
    --activation_func swish \
    --epochs 20 \
    --batch_size 1 \
    --seed 42 \
    --optimizer False
# srun python -u train.py --use_wandb online --model_type IPC --normalize_msg False --dataset_transform none --numbers_list 0,1,3,4,5,6,7 --N 20 --supervision_label_val 10 --num_internal_nodes 1500 --graph_type stochastic_block --weight_init 0.001 --T 50 --lr_values 0.1 --lr_weights 0.0001 --activation_func swish --epochs 20 --batch_size 4 --seed 42 --optimizer False