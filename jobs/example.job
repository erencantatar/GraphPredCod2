#!/bin/bash

#SBATCH --partition=gpu_mig
#SBATCH --gpus=1
#SBATCH --job-name=PC
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=25:00:00
#SBATCH --output=outputs/PC/slurm_output_%A_simple.out

module purge
module load 2022
module load Anaconda3/2022.05

cd /home/etatar/GraphPredCod2/scr

# Activate your environment

source activate PredCod

# experiment 1: own params 
echo "Running simple training"

echo "----PC----"

# experiment 1: own params 
echo "Running simple training"

srun python -u train.py --use_wandb online --model_type IPC --normalize_msg False --dataset_transform none --numbers_list 0,1,3,4,5,6,7 --N 20 --supervision_label_val 10 --num_internal_nodes 1500 --graph_type stochastic_block --weight_init 0.001 --T 50 --lr_values 0.1 --lr_weights 0.0001 --activation_func swish --epochs 20 --batch_size 4 --seed 42 --optimizer False